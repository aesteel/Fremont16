---
title: "Exploration for Data Filtering"
author: "Anna Steel"
date: "August 10, 2016"
output: html_document
---

```{r, include=FALSE} 
# required packages
library(dplyr)
library(sp)
library(rgdal)
library(rgeos)
library(ggplot2)
library(grid) 
library(cowplot)
library(viridis)
```

### Read in Data 
- Open script from Fremont16.Rproj in GitHub to ensure directories are correct
- Creates basic df as well as projects a spatial dataframe
+ currently unable to reproject into UTM; emailed Frank Smith @ VEMCO 8/11/2016
+ result is that the latlong are in WGS84 and the XY are azimuthal. Which is exactly what it says in the 2015 report. nice. 
``` {r, echo=FALSE}
 load("Maestros/alldf.RData")
 options("digits.secs"=6)
 alldf$Time <- as.POSIXct(as.character(alldf$Time), format="%Y-%m-%d %H:%M:%OS", tz = "GMT")

alldf.sp <- SpatialPointsDataFrame(coords = alldf[,c("Longitude","Latitude")], 
              data = alldf, proj4string=CRS("+proj=aeqd +lat_0=38.759985 +lon_0=-121.666908 +x_0=1000 +y_0=1000 +datum=WGS84"))
              # proj4string directly from VEMCO documentation

# alldf.utm <- spTransform(alldf.sp, CRS("+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"))

 # N fish & positions beginning in dataframe
 print(paste0("Prior to filtering, ",nrow(alldf)," total posotions in dataset"))
 print(paste0("Prior to filtering, ",length(unique(alldf$Id))," inidividual fish positioned"))
```

### Initial Data Cleaning
- remove exessively high HPEs (<1000) for ease later
- reduce dataset to only postions recorded after full VPS array was in place (don't yet have removal dates, so not incorporated here)
- other steps to include here?

``` {r, echo=FALSE}
 # excessive HPEs (>1000)
 alldf <- alldf[alldf$Hpes<1000,]  # removes 5 detections
  print(paste0("Removing ",nrow(alldf[alldf$Hpes>=1000,])," positions with HPEs > 1000"))
 
 # incomplete array
 alldfg <- alldf[alldf$Time > as.POSIXct("2016-02-109 14:00:00", tz="GMT"),]
  print(paste0(nrow(alldf) - nrow(alldfg)," positions removed due to incomplete VPS array"))
```

***

### Explore HPEs relationship with measured error for sync and reference tags 
- Only positions with Hpes<1000
- Currently uses Heversine formula with earth's radius est = 6371 km to calc distance between lat-long coords
- Eventually would like to first convert to UTM to faciliate calculating distances between points
- actually, silly girl, use the XY coordinates already in here. Wow. 

``` {r, echo=FALSE, warning=FALSE}
 allsync <- read.csv("C:/Users/Anna/Documents/03_SacBankUSACE/FremontWeir2016/DATA/Positions/AllSyncRef.csv")

 options("digits"=15)
 calibsync <- read.csv("C:/Users/Anna/Documents/03_SacBankUSACE/FremontWeir2016/DATA/AnalysisPack1/CalibratedStationPositions.csv")
   calib.nameindex = read.csv("C:/Users/Anna/Documents/03_SacBankUSACE/FremontWeir2016/DATA/AnalysisPack1/CalibratedStationPositionsIndex.csv")
   calibsync <- merge(calib.nameindex, calibsync, by="Name", all.x=T); names(calibsync) <- c("Name","Id","LongId","TrueLat","TrueLon","X","Y")
  
 allsync.calib <- merge(allsync, calibsync[,c("Id","TrueLat","TrueLon")], by="Id", all.x=T) 
  allsync.calib <- allsync.calib[allsync.calib$Hpes<1000,]

#   # convert to utm and calc dist btwn detected and calibrated points
#  ### currently doesn't work; email to Frank Smith (vemco) for help 8/11/2016
#   synccalib.sp <-  SpatialPointsDataFrame(coords = allsync.calib[,c("TrueLon","TrueLat")], 
#                           data = allsync.calib[,c("Id","Time","Hpes")], 
#                           proj4string=CRS("+proj=aeqd +lat_0=38.759985 +lon_0=-121.666908 +x_0=1000 +y_0=1000 +datum=WGS84"))
#   synccalib.utm <- spTransform(synccalib.sp, CRS("+proj=utm +zone=10 +ellps=GRS80 +units=m +no_defs")) #EPSG:3157
#   syncdet.sp <-  SpatialPointsDataFrame(coords = allsync.calib[,c("Longitude","Latitude")], 
#                           data = allsync.calib[,c("Id","Time","Hpes")], 
#                           proj4string=CRS("+proj=aeqd +lat_0=38.759985 +lon_0=-121.666908 +x_0=1000 +y_0=1000 +datum=WGS84"))
#   syncdet.utm <- spTransform(syncdet.sp, CRS("+proj=utm +zone=10 +ellps=GRS80 +units=m +no_defs")) #EPSG:3157
#      utm.error = sqrt((synccalib.utm$TrueLat - syncdet.utm$Latitude)^2 + (synccalib.utm$TrueLon - syncdet.utm$Longitude)^2)

 
  # Calculate distance btwn lat-long coords
  # Use Haversine formula, as found on "andrew.hedges.name/experiments/haversine"; doesn't account for elipsoid 
  
    # function to convert degrees to radians
        deg2rad <- function(deg) {(deg * pi) / (180)}
    # use function in Haversine formula to calculate distanced between points
         dlat = deg2rad(allsync.calib$Latitude - allsync.calib$TrueLat)
         dlon = deg2rad(allsync.calib$Longitude - allsync.calib$TrueLon)
         a = (sin(dlat/2))^2 + cos(allsync.calib$TrueLat) * cos(allsync.calib$Latitude) * (sin(dlon/2))^2
         c = 2 * atan2(sqrt(a), sqrt(1-a))
         R = 6371000 # est m radius of earth @ equator
         error = R * c
    allsync.calib$error_m <- error
  
  # point data for measured error vs HPEs   
   plot(allsync.calib$error_m ~ allsync.calib$Hpes, xlim=c(0,1000), ylab="measured error", xlab="HPEs")
    
  # calculate average errors for binned data
    hpetable = dplyr::select(allsync.calib, error_m, Hpes)
    hpetable = hpetable[hpetable$Hpes<=50,]     # subset b/c 99.9% of all positions have HPEs<43

   binsize=0.25
    breaks = binsize*(c(0:(50/binsize)))[1:200]
    hpetable$group = findInterval(hpetable$Hpes,breaks)

   binstats = hpetable %>%
     group_by(group) %>%
     summarize( meanHPEm=mean(error_m), 
                medianHPEm=median(error_m),
                quant90HPEm=quantile(error_m, 0.9),
                quant95HPEm=quantile(error_m, 0.95))%>%
     mutate(bincent = (binsize*group)-(binsize/2)) %>%
     data.frame()

  # plot bin moments
   viridiscol = viridis(4)
    hpestats = ggplot(binstats, aes(x=bincent, y=quant95HPEm)) + #95%
         geom_point(aes(x=bincent, y=meanHPEm), colour=viridiscol[1]) + 
         geom_point(aes(x=bincent, y=medianHPEm), colour=viridiscol[2]) + 
         geom_point(aes(x=bincent, y=quant90HPEm), colour=viridiscol[3]) + 
         #geom_point(aes(x=bincent, y=quant95HPEm), colour=viridiscol[4]) + 
         geom_smooth(aes(x=bincent, y=meanHPEm), colour=viridiscol[1], se=FALSE) + 
         geom_smooth(aes(x=bincent, y=medianHPEm), colour=viridiscol[2], se=FALSE) + 
         geom_smooth(aes(x=bincent, y=quant90HPEm), colour=viridiscol[3], se=FALSE) + 
         #geom_smooth(aes(x=bincent, y=quant95HPEm), colour=viridiscol[4], se=FALSE) + 
         geom_hline(yintercept = 5, lty=2) + geom_hline(yintercept = 10, lty=3) +
         annotate("text",x=0, y=90, label="Sync and Reference\nTag Positions", size=5,adj=0) + 
         annotate("text",x=-0.25, y=7.5, label="Error = 5m", colour="gray70", size=3,adj=0) + 
         annotate("text",x=-0.25, y=12, label="Error = 10m", colour="grey70", size=3, adj=0) + 
         annotate("text",x=1, y=0, label="mean", colour=viridiscol[1]) + 
         annotate("text",x=3, y=0, label="median", colour=viridiscol[2]) + 
         annotate("text",x=5, y=0, label="90%ile", colour=viridiscol[3]) + 
         #annotate("text", x=7, y=0, label="95%ile",colour=viridiscol[4]) +
        theme_bw() + ylab("Measured Error") + xlab("Calculated HPEs") + xlim(-0.5,8) + ylim(0,100)
    
    # create a table to plot the % of data at each threshold of HPEs  (time consuming step)
    cumperc = data.frame(HPEs = seq(0,50, by=.25), CumPos = NA, PercPos=NA)
    for(i in 1:nrow(cumperc)) {cumperc[i,2] <- nrow(allsync[allsync$Hpes<cumperc[i,1],])}
    cumperc$PercPos = cumperc$CumPos / nrow(allsync)
    
    hpeperc = ggplot(cumperc, aes(x=HPEs-.25/2, y=PercPos, width = .225)) + geom_bar(stat="identity", fill="grey80") + theme_bw() + xlim(-0.5, 8) + xlab("Calculated HPEs") + ylab("% of Positions Retained")
    
    ggdraw() + draw_plot(hpestats, 0.05,.3,0.95,.7) + draw_plot(hpeperc, 0.05, 0, 0.95, .275) +
      draw_plot_label(c("A","B"),c(0,0), c(.95,.20), size=12)
    
    
    print(paste0("At threshold of HPEs<1, mean measured error (m) of sync/ref positions = ",round(mean(allsync.calib$error_m[allsync.calib$Hpes<1]),2)))
    print(paste0("At threshold of HPEs<1, median measured error (m) of sync/ref positions = ",round(median(allsync.calib$error_m[allsync.calib$Hpes<1]),2)))
    print(paste0("At threshold of HPEs<1, 90%ile of measured error (m) of sync/ref positions = ",round(quantile(allsync.calib$error_m[allsync.calib$Hpes<1],0.9),2)))
    print(paste0("At threshold of HPEs<1, ", round(nrow(allsync.calib[allsync.calib$Hpes<1,])/nrow(allsync.calib)*100,2), "% of sync/ref positions retained"))     
```    
Based on these graphics I will use a HPE filtering threshold of HPE=1; this seems to be a nice tradeoff between precision (mean ~ 5m in HPE bin 0.75-1) and quantity of data (~80% of data retained). 

***

### Distribution of HPEs in fish positions (Similiar to Fig 9 in 2015 report)
- Eventually will project remaining and removed positions into spatial data to make maps cleaner and integrate river bank
+ currently, the reprojection from VEMCO's aeqd is not working (see above)
``` {r, echo=FALSE, warnings=FALSE, fig.height=9}
  # Fig 9, similar  
  nHighHpe <- nrow(alldfg[alldfg$Hpes>=5,])
  nLowHpe <- nrow(alldfg[alldfg$Hpes<5 & alldfg$Hpes>=1,])
  nKeepHpe <- nrow(alldfg[alldfg$Hpes<1,])
  
  percHigh <-(nHighHpe/(nLowHpe+nHighHpe+nKeepHpe))*100
  percLow <-(nLowHpe/(nLowHpe+nHighHpe+nKeepHpe))*100
  percKeep <- (nKeepHpe/(nLowHpe+nHighHpe+nKeepHpe))*100
    
    highhpe=ggplot(alldfg[alldfg$Hpes>=5 & alldfg$Hpe<50,], aes(y=Latitude, x=Longitude, colour=Hpes)) + geom_point(size=1.5) + 
      scale_colour_gradient2(name="HPEs", low = "green3", mid="yellow", high = "red", midpoint=15, space = "rgb", na.value = "grey50", guide = "colourbar") +
      ggtitle(paste0("Positional HPEs > 5: ",round(percHigh,1),"% of all positions")) +
      scale_y_continuous(breaks=seq(38.758,38.764,0.001)) + 
      scale_x_continuous(breaks=seq(-121.672, -121.664, 0.001)) +
      coord_fixed() + 
      theme_bw() + theme(title=element_text(vjust=2), axis.title.x=element_text(vjust=-.5),axis.title.y=element_text(vjust=1))
    
    lowhpe=ggplot(alldfg[alldfg$Hpes<5 & alldfg$Hpes>=1,], aes(y=Latitude, x=Longitude, colour=Hpes)) + geom_point(size=1.5) + 
      scale_colour_gradient2(name="HPEs", low = "green3", mid="yellow", high = "red", midpoint=3, space = "rgb", na.value = "grey50", guide = "colourbar") +
      ggtitle(paste0("Positional HPEs from 1 to 5: ",round(percLow,1),"% of all positions")) +
      scale_y_continuous(breaks=seq(38.758,38.764,0.001)) + 
      scale_x_continuous(breaks=seq(-121.672, -121.664, 0.001)) +
      coord_fixed() + 
      theme_bw() + theme(title=element_text(vjust=2), axis.title.x=element_text(vjust=-.5),axis.title.y=element_text(vjust=1))
    
    keephpe=ggplot(alldfg[alldfg$Hpes<1,], aes(y=Latitude, x=Longitude, colour=Hpes)) + geom_point(size=1.5) + 
      scale_colour_gradient2(name="HPEs", low = "green3", mid="yellow", high = "red", midpoint=.8, space = "rgb", na.value = "grey50", guide = "colourbar") +
      ggtitle(paste0("Positional HPEs < 1: ",round(percKeep,1),"% of all positions")) +
      scale_y_continuous(breaks=seq(38.758,38.764,0.001)) + 
      scale_x_continuous(breaks=seq(-121.672, -121.664, 0.001)) +
      coord_fixed() + 
      theme_bw() + theme(title=element_text(vjust=2), axis.title.x=element_text(vjust=-.5),axis.title.y=element_text(vjust=1))
    
    png("Graphics/Figure9_HPE_Spatial_Distn.png", width=6, height=9, units="in", res=600)
     plot_grid(highhpe, lowhpe, keephpe, nrow=3, ncol=1)
    dev.off()
```

###  Implement HPEs threshold in filtering
- This DOES NOT match the report from VEMCO (they report 106,529 or 87% after filtering to HPE<1)
- I need to get the tagID metadata from someone; suspect there are tags here that aren't fish tags
```{r, echo=FALSE, warnings=FALSE}  
  reddf = alldfg[alldfg$Hpes < 1,]
   print("After filtering @ HPEs<1, dataset retained:")
   print(paste0("  ",nrow(reddf)," positions,")) # 110,211  
   print(paste0("  ",round(nrow(reddf)/nrow(alldfg)*100,2), "% of fish tag positions"))  # 84.35%
   print(paste0("  ",length(unique(reddf$Id))," individual fish"))  # 438
   
  reddf.sp <- SpatialPointsDataFrame(coords = reddf[,c("Longitude","Latitude")], data = reddf, proj4string=CRS("+proj=aeqd +lat_0=38.759985 +lon_0=-121.666908 +x_0=1000 +y_0=1000 +datum=WGS84"))
   # proj4string directly from VEMCO documentation
  
  dropdf = alldfg[alldfg$Hpes >=1,]
  dropdf.sp <- SpatialPointsDataFrame(coords = dropdf[,c("Longitude","Latitude")], data = dropdf, proj4string=CRS("+proj=aeqd +lat_0=38.759985 +lon_0=-121.666908 +x_0=1000 +y_0=1000 +datum=WGS84"))
   # proj4string directly from VEMCO documentation
 
```

Here is an excerpt from VEMCO's results document that is returned with the post-processed VPS dataset, regarding thier estimate of the precision of the fish positions:

> Fish tag precision is estimated here using a simple method of comparing pairs of calculated positions
> that are very close in time, based on the knowledge that over a short period of time a fish will travel a
> relatively short distance. The time durations between successive transmissions of a fish tag in this study
> follow a pseudorandom sequence, with a minimum of 1.0 seconds, a maximum of 2.0 seconds, and an
> average of 1.5 seconds.
> For each of the HPEs filters, the retained positions are analyzed as follows:
> • Pairs of positions from the same transmitter that are within 2.0 seconds of each other are
> identified, and the horizontal distances between these pairs of positions are calculated
> • Selected percentiles of these horizontal distances are calculated
> The following is a summary of these analyses:
> HPEs  # Pos  % pos  50%ile 80%ile 90%ile 95%ile
> 0.2   25792   21%   1.34    2.04    2.56   3.16
> 0.5   83658   68%   1.57    2.54    3.45   4.62
> 1.0  106529   87%   1.68    2.93    4.21   5.86
> For example, using an HPEs filter of 1.0, half of the pairs of calculated positions that are within 2.0
> seconds of each other are less than 1.68 metres apart, and 80% are within 2.93m.
> Note that these statistics cannot be compared directly with the corresponding statistics for sync and
> reference tags because they include a component based on an average of 1.5 seconds of fish motion.

***

### Distributions of individual detections/GoodBasic positions for each calculated fish location:
- not of much interest but code was already written
``` {r, echo=FALSE} 
  ### not in report ###
 par(mfrow=c(2,2))
  hist(alldfg$GoodBasicCount, breaks=25, main="All Positions:\nNumber of Good Basic positions \nper estimated position", xlab="N Good Basic Positions", xlim=c(0,25))
  hist(reddf$GoodBasicCount, breaks=25, main="Positions HPEs<1:\nNumber of Good Basic positions \nper estimated position", xlab="N Good Basic Positions", xlim=c(0,25))

  hist(alldfg$DetectionsCount, breaks=25, main="All Positions:\nNumber of Detections \nper estimated position", xlab="N Detections", xlim=c(0,25))
  hist(reddf$DetectionsCount, breaks=25, main="Positions HPEs<1:\nNumber of Detections \nper estimated position", xlab="N Detections", xlim=c(0,25))
```

### Positions remaining per fish (Figs 8 and 10 in 2015 report)
- considered positions per fish before filtering by HPE and after
+ plots tracks of outliers to examine for predator-like behavior patters
+ 'outliers' defined according to standard boxplot metrics: all those points greater than 1.5*IQR + 75%ile of the data.
- plots percent of positions remaining for individual fish after filtering at HPE<1 (Fig 8)
```{r, echo=FALSE, fig.height=8, fig.width=7}
 # prior to HPE filtering
 all.npf = alldfg %>%
   group_by(Id) %>%
   summarize(npos.all=n())%>%
   data.frame()

  summary(all.npf$npos.all)
  
  png("Graphics/Figure8a_HPE_PosPerFish.png", width=6, height=5, units="in", res=600)
   hist(all.npf$npos.all, xlim=c(0,1000), breaks=250, ylim=c(0,110),
        xlab=c("Number of Positions"), main="Positions recorded per fish\nprior to HPE filtering")  
    text(x=800, y=40, "Removed two individual tags\nw/ > 5000 detections", font=3)
  dev.off()

  outliers.pre = all.npf[all.npf$npos.all %in% sort(boxplot.stats(all.npf$npos.all)$out),]
      
  ggplot(data=alldfg[alldfg$Id %in% outliers.pre$Id,], aes(x=Longitude, y=Latitude)) + geom_point() +
    facet_wrap(~Id, ncol=4) + ggtitle("Tracks of outliers, positions not filtered")

 # after HPE filtering
 red.npf = reddf %>%
   group_by(Id) %>%
   summarize(npos.red= n()) %>%
   data.frame()
     
  summary(red.npf$npos.red)   
  
  png("Graphics/Figure8b_HPE_PosPerFish.png", width=6, height=5, units="in", res=600)
    hist(red.npf$npos.red, xlim=c(0,1000), breaks=100, ylim=c(0,110), 
         xlab=c("Number of Positions"), main="Positions recorded per fish\nafter HPE filtering")  
     text(x=800, y=40, "Removed two individual tags\nw/ > 2000 detections", font=3)
  dev.off()
  
  outliers.post = red.npf[red.npf$npos.red %in% sort(boxplot.stats(red.npf$npos.red)$out),]
        
  ggplot(data=reddf[reddf$Id %in% outliers.post$Id,], aes(x=Longitude, y=Latitude)) + geom_point() +
              facet_wrap(~Id, ncol=4) + ggtitle("Tracks for outliers, positions filtered HPEs<1")
```
```{r, echo=FALSE, warnings=FALSE}
  # percent of positions remaining per individual fish (Fig 10)
  
 comp.npf = merge(all.npf, red.npf, by="Id")
 comp.npf$perc.remain = comp.npf$npos.red / comp.npf$npos.all
 
 filtlevel = ggplot(data = alldfg, aes(Hpes)) + 
    geom_histogram(binwidth=.2, col=I("black"), fill="grey95") + 
    ggtitle("Calculated HPEs, all positions") + 
    scale_x_continuous(breaks=seq(0,10,2), limits=c(0,10)) + 
    xlab("HPEs") + ylab("Frequency") + 
    theme_bw() + 
    theme(title=element_text(vjust=2), 
          axis.title.x=element_text(vjust=-.5),
          axis.title.y=element_text(vjust=1.2),
          plot.margin=unit(c(1,1,1.25,1), "cm")) +
    geom_vline(xintercept = 1, col="red", lty=2) + 
    annotate("text",x=1.1, y=50100, label="HPEs = 1", col="red", adj=0, size=4)

 filt.ppf = ggplot(data = comp.npf, aes(npos.red)) + 
    geom_histogram(binwidth=25, col=I("black"), fill="grey95") + 
    ggtitle("Filtered at HPEs<1:
            
Positions per Fish") +  
    scale_x_continuous(breaks=seq(0,500,100), limits=c(0,500)) + 
    scale_y_continuous(breaks=seq(0,70,20), limits=c(0,70)) + 
    xlab("N Positions") + ylab("Frequency") + 
    theme_bw() + 
    theme(title=element_text(vjust=2), 
          axis.title.x=element_text(vjust=-.5),
          axis.title.y=element_text(vjust=1.2),
          plot.margin=unit(c(.1,1,.75,.5), "cm"))

 filt.proprem = ggplot(data = comp.npf, aes(perc.remain)) + 
    geom_histogram(binwidth=.025, col=I("black"), fill="grey95") + 
    ggtitle("Proportion Positions\nRemaining per Fish") + 
    scale_x_continuous(breaks=seq(0,1,.2), limits=c(0,1)) + 
    scale_y_continuous(breaks=seq(0,85,20), limits=c(0,85)) + 
    xlab("Proportion") + ylab("Frequency") + 
    theme_bw() + 
    theme(title=element_text(vjust=2), 
          axis.title.x=element_text(vjust=-.5),
          axis.title.y=element_text(vjust=1.2),
          plot.margin=unit(c(.1,1,.75,.5), "cm"))

        
       png("Graphics/Figure10_Filtered_ComboFigure.png", width=8, height=4.75, units="in", res=300)
        ggdraw() + 
          draw_plot(filtlevel, x=0,y=0,width=.6, height=1) + 
          draw_plot(filt.ppf, x=.6,y=.475,width=.4, height=0.45) + 
          draw_plot(filt.proprem, x=.6,y=0.025,width=.4, height=0.45) +  
          draw_plot_label(label=c("A","B","C"), x=c(0.05,0.62,0.62), y=c(.975,.88,.45), size=16)
        dev.off()
```
 
### Look at fish which >40% positions removed
- how many are there?
- are the tracks indicative of predator behavior?
- where are the errors?
```{r, echo=FALSE, warnings=FALSE}
  # how many?      
   poorHpes = comp.npf[comp.npf$perc.remain<=.6,]  # 2 fish
      print(paste0("Only ",nrow(poorHpes)," fish with >40% of positions removed"))
   poor.dfg = alldfg[alldfg$Id %in% poorHpes$Id,]

  # where are the errors in the 'bad' tracks?
  ggplot(data=poor.dfg[order(poor.dfg$Hpes),], aes(x=Longitude, y=Latitude, color=(Hpes))) + 
    geom_point() + coord_fixed() + 
    facet_wrap(~Id, ncol=4) + 
    scale_colour_gradientn(colours=rev(viridis(5)))
  
  # does the track change significantly when the poor Hpes points are removed? No
  poor.pre = ggplot(data=alldfg[alldfg$Id %in% poorHpes$Id,], aes(x=Longitude, y=Latitude)) + geom_point() + 
    facet_wrap(~Id, ncol=4) + ggtitle("'Poor' tracks with no filtering")
  poor.post = ggplot(data=alldfg[alldfg$Id %in% poorHpes$Id & alldfg$Hpes<1,], aes(x=Longitude, y=Latitude)) + geom_point() + facet_wrap(~Id, ncol=4) + ggtitle("'Poor' tracks filtered at HPEs < 1")

  plot_grid(  poor.pre, poor.post, ncol=1, nrow=2)
```  


### Look at fish tracks for potential predators
- high number of detections
+ 1st plot shows tracks for fish with the top 5% of recorded positions 
- long passage time
- movement upstream 
```{r, echo=FALSE, warnings=FALSE}
   # track of top 5% N positions, color coded by hour of day
   highN.red = red.npf[red.npf$npos.red >= quantile(red.npf$npos.red, .95),]
   ggplot(data=reddf[reddf$Id %in% highN.red$Id,], aes(x=Longitude, y=Latitude)) +
     geom_path(aes(colour=as.POSIXlt(Time)$hour)) + 
     facet_wrap(~Id, ncol=5) + scale_colour_gradientn(colours=rainbow(6), name="Hour of Day") + 
     ggtitle("Highest 5% N positions, positions filtered HPEs<1") + 
     theme(axis.text.x = element_text(angle = 90, hjust = 1))

  # Pull arrival and departure times and locations
   fl.df = reddf %>%
      group_by(Id) %>%
      slice(c(1,n()))
   fl.df = as.data.frame(fl.df)
   fl.df$fl = rep(c("F","L"),nrow(fl.df)/2)  
  
    ff = fl.df[fl.df$fl=="F",c("Id","Time","Latitude","Longitude")] 
     names(ff) = c("Id","F.time","F.lat","F.long")
    ll = fl.df[fl.df$fl=="L",c("Id","Time","Latitude","Longitude")]
     names(ll) = c("Id","L.time","L.lat","L.long")
  
   fl.df2 = merge(ff,ll)
  
   # calculate passage time through array, and look at long pass times
   fl.df2$arraytime_min = as.numeric(difftime(fl.df2$L.time, fl.df2$F.time))
   
   hist(fl.df2$arraytime_min, breaks=5000, xlim=c(0,300), 
        main="Passage time for all fish, filtered at HPEs<1", xlab="Passage Time (min)")
    long.fish = fl.df2[fl.df2$arraytime_min > 150,]$Id
      # 36379 36398 36472 36483 36612 36675 65068 65069 65070 65073 65124
   print(paste0(length(long.fish)," individual tags with >150 min passage time"))
    
   # calculate location of final detection; upstream?  
   hist(fl.df2$L.long, xlab="Longitude (upstream to downstream)", 
      main="Histogram of final detection location")
   abline(v=-121.6679,col="red", lty=2)
    upfish = fl.df2[fl.df2$L.long < -121.6679,]$Id
      # 36472 65124
    print(paste0(length(upfish)," fish exited at upstream end of array"))
```

### Last to-do: Use these graphics to decide which tags to evaluate further for evidence of predation
my first instict is none, or very very few