{
    "contents" : "\n## Second filtering phase ##\n## Using ltraj object to identify biologically unreasonable positions, based on movement speeds ##\n\nlibrary(adehabitatLT)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rgdal)\nsource(\"Functions_General.R\")\n\n\n# read in HPE/pred filtered dataset (see \"DataFilter.R\" in this project)\n  options(\"digits\"=20)\n  reddf= read.csv(\"DATA-output/Output_PrelimFilter_for_Bertrand_noscout.csv\")\n    options(digits.secs=6)\n    reddf$DateTime = as.POSIXct(reddf$DateTime, format=\"%Y-%m-%d %H:%M:%OS\", tz=\"GMT\")  # even with this code seem to lose the miliseconds\n\n  reddf = reddf[order(reddf$TagID, reddf$DateTime),]  # Critical to order this properly for the ordered step analysis below (TypeI)\n\n  reddf$IDcol = 1:nrow(reddf)\n\n\n# convert the Lat Long into UTMs using 'sp'\n  ixy = data.frame(reddf[,c(\"IDcol\",\"Lat\",\"Long\")])\n    coordinates(ixy) = c(\"Long\",\"Lat\")   # or this, exactly the same: coordinates(xy) = ~ Long + Lat \n    proj4string(ixy) = CRS(\"+init=epsg:4326\")  # may be incorrect, but the version provided by VEMCO doesn't convert to UTMs\n      # proj4string(ixy) = CRS(\"+proj=aeqd +lat_0=38.759985 +lon_0=-121.666908 +x_0=1000 +y_0=1000 +datum=WGS84\")\n\n  utms <- spTransform(ixy, CRS(\"+proj=utm +zone=10 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"))\n  reddf2 = merge(reddf, utms, by=\"IDcol\")\n   names(reddf2) = c(\"IDcol\",\"TagID\",\"datetime\",\"x\",\"y\",\"lat\",\"long\",\"HPE\",\"run\",\"E\",\"N\")\n  \n\n# convert to class ltraj - AWESOME!\n   # as a TypeII track where time is recorded\n    red.ltraj2 = as.ltraj(xy=reddf2[,c(\"E\",\"N\")], date=reddf2$datetime, id=reddf2$TagID, infolocs = reddf2[,c(\"TagID\",\"run\",\"HPE\")])\n \n   # and change this to a basic dataframe for assessment with tools I already have. \n     red2 = ld(red.ltraj2)\n \n# calculate speed for each step (taken after each position)\n  red2$spd_mps = red2$dist / red2$dt\n    # remember, in ltraj objects the distance estimate is the distance of the step traveled AFTER the point specified in that line\n    #  and the time also corresponds to the time for the subsequent step (step after point coordiates)\n\n\n          \n# create new columns in dataframe\n red2$prevspd = NA\n red2$badpos = NA\n\n# put the previous speed on the same line as the current speed\n red2$prevspd <- c(NA,red2$spd_mps[1:(nrow(red2)-1)])\n  \n# if there one speed less than the cuttoff, consider the detection okay (in reality may not be, but it's gonna be more complicated)\n# if two subsequent speeds are greater than the cuttoff, we have a bad detection\n#    - the bad point should have high speeds in the line before it (step leading to it) and in its line (step leading from it)\n#    - so it is the second high value in a pair that is in the same line as the bad position\n red.gp = red2 %>%\n   group_by(id) %>%\n   mutate(badpos=(spd_mps>5 & prevspd>5) )  ###### is 5 mps a reasonable cutoff? What should we use? ######\n rednew = as.data.frame(red.gp)\n\n# remove 'bad' positions --> as of June 3, 2015 this removed 322 positions (0.444%) with cutoff of 5mps; removes 414 with cutoff of 4mps\n badpos = rednew[rednew$badpos==TRUE,]  # included 117 fish\n   badpos.fish = summarize(group_by(badpos, id), nremoved=n())\n\n red2new = rednew[rednew$badpos==FALSE,]\n\n# reduce to basic data, make the coords spatial, and convert to ltraj\n red2base = red2new[c(\"x\",\"y\",\"date\",\"id\",\"run\",\"HPE\")]\n  red2base = red2base[!is.na(red2base$x),]  # somehow the previous processs adds and NA into the dataframe\n  red2base$date = as.POSIXct(red2base$date)\n  ixy = data.frame(red2base[,c(\"id\",\"x\",\"y\")])\n    coordinates(ixy) = c(\"x\",\"y\")\n    proj4string(ixy) = CRS(\"+proj=utm +zone=10 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\n  \n red3 = as.ltraj(xy=red2base[,c(\"x\",\"y\")], date=red2base$date, id=red2base$id, infolocs = red2base[,c(\"id\",\"run\",\"HPE\")])\n\n# convert back to dataframe \n red3.df = ld(red3)\n   red3.df$spd_mps = red3.df$dist/red3.df$dt\n\n# check for improved speeds\n range(red3.df$spd_mps, na.rm=T)  # STILL has a speed of 73.1 mps. =/\n\n trash = red3.df[red3.df$spd_mps>5,]\n   trash = trash[!is.na(trash$id),]\n   dim(trash)  # still 368 lines with high speeds. better, but not done yet. =/\n   ht(trash)\n\n        # code to explore the points that still have SUPER high speeds \n          trash=red3.df[red3.df$spd_mps>50,]  # only 3 tags remaining with speeds >50mps\n          trashtab = data.frame(table(trash$id))\n          trashtab = trashtab[trashtab$Freq!=0,]\n          trashid.freq1 = trashtab[trashtab$Freq==1,\"Var1\"]\n\n          trash.freq1 = red3.df[red3.df$id %in% trashid.freq1,]        \n          trash.freq1.ex = trash.freq1[trash.freq1$id == 56882,] \n           plot(trash.freq1.ex$x, trash.freq1.ex$y, type=\"o\")\n           points(x=trash.freq1.ex[trash.freq1.ex$spd_mps>10,\"x\"], \n                  y=trash.freq1.ex[trash.freq1.ex$spd_mps>10,\"y\"], col=\"green3\", pch=16, cex=1.5)\n           points(x=trash.freq1.ex[trash.freq1.ex$spd_mps==max(trash.freq1.ex$spd_mps, na.rm=T),\"x\"], \n                  y=trash.freq1.ex[trash.freq1.ex$spd_mps==max(trash.freq1.ex$spd_mps, na.rm=T),\"y\"], col=\"red\", pch=16, cex=1.5)\n           plot(trash.freq1.ex$x, trash.freq1.ex$y, type=\"o\", xlim=c(615800, 615920), ylim=c(4290950, 4291080))\n          row.names(trash.freq1.ex) = 1:nrow(trash.freq1.ex )\n            trash.freq1.ex[135:160,]\n         ### manual point removal might be necessary? \n        # tagID 37206, date = c(\"2015-01-29 15:00:25.810326\" : \"2015-01-29 15:00:38.375442\"), total of 6 wonky points\n        # tagID 51649, date = c(\"2015-02-04 04:22:45.090825\", \"2015-02-04 04:22:53.891988\", \"2015-02-04 04:23:01.155149\", \"2015-02-04 04:23:13.386168\"), total of four back-step points that don't fit the line; ones between do\n        # tagID 56882, date = c(\"2015-02-04 14:18:57.955996\", \"2015-02-04 14:19:06.651381\", \"2015-02-04 14:19:44.003906\")\n         ### All three of these have nice backbones of tracks but with a couple rogue points as clearly erronious backsteps. \n         ###  and interestingly, they tend to be all in the same area of the array. I've identified the timestamps associated with these extreme extreme data, but there are likely others too.\n         ### To see if these problems get muted in the discretization later on, I should compare the tracks for these three fish, discretized from simple filtered tracks and from manual filtered tracks. \n          #   Plan, as of Sept 21, 2015.\n\n\n          \n          ## repeat: \n          # put the previous and next speeds on the same line as the current speed\n           red3.df$prevspd <- c(NA,red3.df$spd_mps[1:(nrow(red3.df)-1)])\n           red3.df$prevspd2 <- c(NA,NA,red3.df$spd_mps[1:(nrow(red3.df)-2)])\n           red3.df$nextspd <- c(red3.df$spd_mps[2:(nrow(red3.df))],NA)\n           red3.df$nextspd2 <- c(red3.df$spd_mps[3:(nrow(red3.df))],NA,NA)\n\n          # look again\n           trash = red3.df[red3.df$spd_mps>5,]\n             trash = trash[!is.na(trash$id),]\n             dim(trash); ht(trash)\n\n          # and check one example to understand what's happening\n            plotdat = red3.df[red3.df$id==59072,]\n            windows()\n                plot(plotdat$x, plotdat$y,type=\"o\")\n                plot(plotdat$x, plotdat$y,type=\"o\", xlim=c(615800, 615900), ylim=c(4290940, 4291000))\n                ## the track looks normal, then there is one wonky spot with ~ 8 points in a jumble. How do fix it?\n\n\n         ## For now, I'll just work with this funky dataset, but need to return to it and sort things out. \n         ##  There are 195 different tracks with at least one eyebrow raiser (mps>5) \n\n\n\n### EXPORT FILTERED DATA ###\n  write.csv(red3.df, \"DATA-output/TrajectoryMetricsFiltered_Time.csv\", row.names=FALSE)\n\n    # and summarize this dataset:\n      dim(red3.df)  # 72,163 positions total\n      length(unique(red3.df$id))  # 481 fish\n        red3.fish = summarize(group_by(red3.df, id), ndetect=n())\n        hist(red3.fish$ndetect, xlim=c(0,500), col=\"grey90\",\n             xlab=\"N Positions\", main=\"Number of positions per fish\\n post-filtering\")\n        mean(red3.fish$ndetect)   # 150.0\n        median(red3.fish$ndetect) # 144.0\n\n    # and reformat it to match previous data exported for Bertrand\n        red3.df$IDcol = 1:nrow(red3.df)\n        red3.id = data.frame(red3.df[,c(\"IDcol\",\"x\",\"y\")])\n          coordinates(red3.id) = c(\"x\",\"y\")   # or this, exactly the same: coordinates(xy) = ~ Long + Lat \n          proj4string(red3.id) = CRS(\"+proj=utm +zone=10 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")#   \"+init=epsg:4326\")  # may be incorrect, but the version provided by VEMCO doesn't convert to UTMs\n          \n        latlongs <- spTransform(red3.id, CRS(\"+init=epsg:4326\"))\n        red3.latlong = merge(red3.df, latlongs, by=\"IDcol\")\n        \n        red4.df = red3.latlong[,c(\"id\",\"date\",\"x.x\",\"y.x\",\"y.y\",\"x.y\",\"HPE\")]\n          names(red4.df) = c(\"TagID\",\"DateTime\",\"Easting\",\"Northing\",\"Lat\",\"Long\",\"HPE\")\n  \n          # add in run, FL, and release group\n            fishdat = read.csv(\"DATA/Maestro_tagging_WRC-LFC.csv\")\n              fishdat = fishdat[,c(\"ID.Tag\",\"Species\",\"RelEv\",\"Fork.Length\")]\n\n        red5.df = merge(red4.df, fishdat, by.x=\"TagID\",by.y=\"ID.Tag\", all.x=T)\n           names(red5.df)[8] = \"Run\"\n           names(red5.df)[10] = \"FLmm\" \n           \n        write.csv(red5.df, \"DATA-output/Output_FullFiltered_for_Bertrand.csv\")\n              \n\n# make example plot to show the data that is being removed - track with the MOST detections removed (when threshold was 5mps)\n  ex.unf = red2[red2$id==51099,]\n  ex.filt = red3.df[red3.df$id==51099,]\n  windows(); par(mfrow=c(1,2))\n   plot(ex.unf$x, ex.unf$y, main=\"Unfiltered\", type=\"l\", lwd=1, xlab=\"Eastings\",ylab=\"Northings\")\n     points(ex.unf$x, ex.unf$y, pch=1, cex=.6, col=\"grey60\")\n   plot(ex.filt$x, ex.filt$y, main=\"Filtered\", type=\"l\", lwd=1, xlab=\"Eastings\",ylab=\"Northings\")\n     points(ex.filt$x, ex.filt$y, pch=1, cex=.8, col=\"grey60\")\n   mtext(\"TagID 51099, WRC\", side=3, line=0, adj=1, cex=.8, font=3)\n\n\n\n\n\n# Make the filtered positions into an ltraj TypeI track where the order is all that is important\n  red.ltraj1 = as.ltraj(xy=red2base[,c(\"x\",\"y\")], date=red2base$date, id=red2base$id, infolocs = red2base[,c(\"run\",\"HPE\")], typeII=FALSE)\n  # convert back to dataframe for export\n   red3.df1 = ld(red.ltraj1)\n     red3.df1$spd_mps = red3.df1$dist/red3.df1$dt\n  \n   write.csv(red3.df1, \"DATA-output/TrajectoryMetricsFiltered_Order.csv\", row.names=FALSE)\n",
    "created" : 1471027390460.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "433397318",
    "id" : "E297E57",
    "lastKnownWriteTime" : 1450809060,
    "path" : "~/03_SacBankUSACE/FremontWeir/DataFilter_Speed.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}