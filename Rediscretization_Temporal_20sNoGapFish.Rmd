---
title: "Rediscretization_Temporal"
author: "Anna Steel"
date: "September 6, 2016"
output: pdf_document
---
```{r, include=FALSE} 
# required packages
library(dplyr)
library(sp)
library(rgdal)
library(rgeos)
library(maptools)
library(ggplot2)
library(grid) 
library(cowplot)
library(viridis)
library(adehabitatLT)
library(adehabitatHR)
library(stringr)
#library(userfriendlyscience)

river3 = readOGR("C:/Users/Anna/Documents/GitHub/Fremont16/GIS/2004_channel","2004_channel_freTightclip")

```


## Rediscretization of Tracks - 20 seconds between positions
- Using primary and secondary filtered data to rediscretize tracks for further analysis
- Tracks with gaps > 150 m have been removed entirely from the analysis. =/
* this threshold can be altered in "Final_Filtering.Rmd" if desired
- Before redistretizing, remove bursts with < 10 positions (too few to rediscretize in adehabitatLT)
- also note that the interval of 20 seconds was selected to be consistent with the 2015 analysis; another script will discretize at 2 seconds to be more consitent with ELAM outputs and USGS analysis

```{r, echo=FALSE}
  options(digits=20) #keep 
  load("Maestros/AllFish_FiltSec5Gaps.RData")  # single object, named red9
 
 dim(red9) # 76269 detections 
    length(unique(red9$id))  # 374 unique fish
    length(unique(red9$burst))  # 374 unique bursts
    
    ndetects.fish = summarize(group_by(red9, id), ndet = n())  
      mean(ndetects.fish$ndet) # 203.9 per fish
      range(ndetects.fish$ndet) # ranges from 22 - 578

```


## Stagger first detection to a random location within the first 100m of start of the array
```{r}
        # stagger first detection across all fish
     ndetects = summarize(group_by(red9, id), ndet = n())  
     quantile(ndetects$ndet, .05)  # fewest 5% of fish have >86 points before discretization

      # look at gaps in detection times across the first 25 detections for each fish
     detect.gaps = red9 %>%
        group_by(id) %>%
        mutate(passage.time = sum(dt, na.rm=T)) %>%
        slice(1:25) %>%
        ungroup() %>%
        group_by(id) %>%
        summarize(mean.gap = mean(dt, na.rm=T), median.gap= median(dt, na.rm=T), max.gap=max(dt, na.rm=T), passage.time = unique(passage.time))
     detect.gaps = as.data.frame(detect.gaps)

      # look at how big the gaps are in relation to total passage time - are the fish half way through before they are detected?
     detect.gaps$percmaxgap = detect.gaps$max.gap / detect.gaps$passage.time
     plot(detect.gaps$percmaxgap ~ detect.gaps$passage.time, ylim=c(0,.5), xlab="passage time", ylab="max gap as percentage\nof individ. passage time")
      abline(h=.1, col="steelblue")  # above line, max gap is > 1/10 of total passage time 
      abline(h=.25, col="green3")  # above line, max gap is > 1/4 of total passage time 
     
     
      # plot first detection of fish
     firsts = as.data.frame(red9 %>% group_by(id) %>% slice(1))
 
     ggplot(data=firsts, aes(y=y, x=x)) + geom_point() +
       coord_fixed() + 
       xlim(c(615450, 615800)) + 
       ylab("Northing") + xlab("Easting") + 
       geom_vline(xintercept = 615475, col="red") + 
       geom_vline(xintercept = 615575, col="green")


      # if first detection has an x value greater than 615575 then keep it (>100m from start)
      #    - there are 64 fish for which this applies
      # otherwise, pick randomly from the points before that location

      # pull number of points for each id that are before the threshold
     n.prethres = red9 %>%
        filter(x<615575) %>%
        group_by(id) %>%
        summarize(n.pre = n())
     n.prethres = as.data.frame(n.prethres)
     
       # add column with the first detection selected for use for that id
       samplefunc = function(x) sample(1:x,1)
       set.seed(23)
       n.prethres$first.det = unlist(lapply(n.prethres$n.pre, samplefunc))

      # subset the original data frame using the randomly sampled first detection
     stag.prep = red9 %>%
        group_by(id) %>%
        mutate(detect.num = 1:n()) 
     stag.prep = as.data.frame(stag.prep)
     reddf.stag = merge(stag.prep, n.prethres, all.x=T)
      reddf.stag[is.na(reddf.stag$first.det),"first.det"] <- 1  # if the first detection was past threshold, automatically use first detection
      reddf.stag = reddf.stag[order(reddf.stag$id, reddf.stag$detect.num),]
      reddf.stag = reddf.stag[reddf.stag$detect.num >= reddf.stag$first.det,]

      # compare first detection location before and after staggering
     windows(); par(mfrow=c(1,2))
     firsts.raw = as.data.frame(red9 %>% group_by(id) %>% slice(1))
     plot(firsts.raw$y ~ firsts.raw$x, xlim=c(615480,616000), ylim=c(4290880, 4291250))
      abline(v=615580, col="red")
     firsts.stag = as.data.frame(reddf.stag %>% group_by(id) %>% slice(1))
     plot(firsts.stag$y ~ firsts.stag$x, xlim=c(615480,616000), ylim=c(4290880, 4291250))
      abline(v=615580, col="red")

      # looks great! The blob of detections right at the beginning is now spread out across the first 100m
      reddf.stag$n.pre <- NULL
      reddf.stag$detect.num <- NULL
```

## Make an ltraj object
```{r}
  red9.ltraj = as.ltraj(xy=reddf.stag[,c("east","north")], date=reddf.stag$date, 
                        id=factor(reddf.stag$id), burst = factor(reddf.stag$burst),
                        infolocs=reddf.stag[,c("Hpes","east","north")])
```

## Discretize in Time
```{r}
  # discretize in time
  red9.trdz = ld(redisltraj(red9.ltraj, u=20, type="time", nnew=50))
   red9.trdz$run = "LFC" # creates a common grouping variable to make UD with all points
   red9.trdz=red9.trdz[order(red9.trdz$id,red9.trdz$date),]
   
 # recalculate migration speed  
   red9.trdz$spd_mps = red9.trdz$dist / red9.trdz$dt
```

```{r, echo=FALSE}
 # SacRiver Stage - pulled from CDEC - ask for QAQC data from DWR if this seems okay 
  frestg = read.csv("C:/Users/Anna/Documents/GitHub/Fremont16/Maestros/FRE_stage_2016study.csv")
  frestg = frestg[!is.na(frestg$stage_ft),]
  frestg = frestg[frestg$stage_ft > 5 ,] # some missing values are recorded as 2 or 5; remove these entirely
   frestg$timePST = str_pad(frestg$timePST, 4, pad = "0")
   frestg$datetimePST = as.POSIXct(paste(frestg$datePST, frestg$timePST), format="%Y%m%d %H%M", tz="Etc/GMT-8")
   frestg$datetimeUTC = as.POSIXct(as.character(frestg$datetimePST + (60*60*8)), tz="GMT")
   frestg = frestg[order(frestg$datetimePST),]
   frestg$stageid = rownames(frestg)
  
 ## merge onto position dataset
   red9.trdz = red9.trdz[order(red9.trdz$date),]

    # magic step! thanks stack exchange!
  red9.trdz$cdecStgIndex <- 
     findInterval( red9.trdz$date, c(-Inf, head(frestg$datetimeUTC,-1))+ c(0,diff(as.numeric(frestg$datetimeUTC))/2 )) 

  red9.trdz = merge( red9.trdz, frestg[,c("stage_ft", "datetimeUTC","stageid")], by.y="stageid", by.x="cdecStgIndex", all.x=T)
  
  red9.trdz = red9.trdz[order(red9.trdz$date),]

  
  # Fish Releases
   fishrel = read.csv("C:/Users/Anna/Documents/GitHub/Fremont16/Maestros/TaggingDataRelEv.csv", 
                     colClasses=c("RelTime"="character"))
    fishrel$RelTime = str_pad(fishrel$RelTime, width=4, side="left", pad="0")
    fishrel$RelTime = str_pad(fishrel$RelTime, width=6, side="right", pad="0")
    
    fishrel$datetime = as.POSIXct(paste(fishrel$RelDate, fishrel$RelTime), format="%Y-%m-%d %H%M%S", tz="Etc/GMT-8")
    #names(fishrel)[3] <- "id"
    names(fishrel)[ncol(fishrel)] <- "datetime.Rel"
     fishrel$RelHr = as.POSIXlt(fishrel$datetime.Rel)$hour
        
  red9.trdz = merge(red9.trdz, fishrel, by="id", all.x=T)
  
  red9.trdz$cdecStgIndex = NULL

  ## write this to file
  saveRDS(red9.trdz, "Maestros/RediscTime_20sNoGapFishStaggered.RData")
```



And finally, output the general metrics about the remaining dataset
```{r}
    dim(red9.trdz) # 14466 detections after discretization
    length(unique(red9.trdz$id))  # 374
    ndetects.discr = summarize(group_by(red9.trdz, id), ndet = n())  
      mean(ndetects.discr$ndet) # 38.68 per fish
      range(ndetects.discr$ndet) # ranges from 15 - 139
    max(red9.trdz$spd_mps, na.rm=T)  # 4.81 mps
```
