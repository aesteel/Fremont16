---
title: "Data Filtering Process, Condensed"
author: "Anna Steel"
date: "August 12, 2016"
output: pdf_document
---

# Filtering of VEMCO post-processed VPS positions

This code runs from the datafiles provided by VEMCO, and builds final datasets for analysis.
It also periodcally outputs descriptive values (e.g.: N fish) to track how filtering alters the dataset.

__The descriptive metrics produced include number of positions, number of fish, and positions per fish__

The filtering includes the following stages, with more details in the scripts noted.
* filters by HPE: see 'Exploration_DataFiltPrimary' for details
* filters by speed: see 'Exploration_DataFiltSec1Speed' for details
* filters for likely predators: see 'Exploration_DataFiltSec2Preds' for details
* splits tracks with large gaps (for subsequent smoothing/rediscretization): see 'Exploration_TrackGapBias' for details

Remember: times are reported in UTC from vemco

```{r, include=FALSE} 
# required packages
library(dplyr)
library(sp)
library(rgdal)
library(rgeos)
library(ggplot2)
library(grid) 
library(cowplot)
library(viridis)
library(adehabitatLT)
```

## Read in Data & Clean for proper dates and TagIDs
- Open script from Fremont16.Rproj in GitHub to ensure directories are correct
- Filter out tags in the 65xxx series
- Filter any tags detected outside of period of complete array (none this year)
- Add UTM coordinates
- Tabulate total fish, total positions, and total positions per fish
``` {r}
 load("Maestros/alldf.RData")
 options("digits.secs"=6)
 alldf$Time <- as.POSIXct(as.character(alldf$Time), format="%Y-%m-%d %H:%M:%OS", tz = "GMT")

 # remove fish tags in the 65xxx series (5 tags)
 alldf <- alldf[alldf$Id<65000,]  # matches VEMCO 
 
 # incomplete array
 alldfg <- alldf[alldf$Time > as.POSIXct("2016-02-109 14:00:00", tz="GMT"),]
  print(paste0(nrow(alldf) - nrow(alldfg)," positions removed due to incomplete VPS array"))
 
 # convert the Lat Long into UTMs using 'sp'
  alldf.sp <- SpatialPointsDataFrame(coords = alldf[,c("Longitude","Latitude")], 
              data = alldf, 
              proj4string=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
        # confirmed string with VEMCO; the XY coords in azimuthal equal area
  options(digits=10)
  alldf.utm <- spTransform(alldf.sp, 
                          CRS("+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"))
  alldf.utm@data[,c("east","north")] <- alldf.utm@coords
  
  alldf.utm = alldf.utm@data   
```

```{r Fig 8, echo=FALSE}
 # N fish & total N positions
 print(paste0("Prior to filtering, ",nrow(alldf)," total positions in dataset"))
 print(paste0("Prior to filtering, ",length(unique(alldf$Id))," individual fish positioned"))

 # N pos per fish 
  all.npf = alldfg %>%
   group_by(Id) %>%
   summarize(npos.all=n())%>%
   data.frame()

   nposplot = ggplot(all.npf, aes(x=npos.all)) + 
     geom_histogram(binwidth=50, fill="grey90", colour="black") +
     xlab("N Positions") + ggtitle("Unfiltered: Positions per fish") +  xlim(0,1000)
   nposplot
 
  png("Graphics/Fig8_Npos_prefilt.png", width=4, height=4, units="in", res=600)
   nposplot
  dev.off()
  
  print("Summary of N positions per fish, after reducing to applicable data")
  summary(all.npf$npos.all)
```

## Primary HPE filter: <0.5 HPEs
```{r hpe 0.5 filt, echo=FALSE}
 reddf = alldfg[alldfg$Hpes < 0.5,]
  
  # N fish & total N positions
   print(paste0(nrow(reddf)," positions")) 
    print(paste0("   ",round(nrow(reddf)/nrow(alldfg)*100,2), "% of fish tag positions"))  
   print(paste0(length(unique(reddf$Id))," individual fish"))  
    print(paste0("   ",round((length(unique(reddf$Id))/length(unique(alldf$Id)))*100,1),"% of individual fish retained "))
   
   
  # N pos per fish after HPE filtering
  red.npf = reddf %>%
   group_by(Id) %>%
   summarize(npos.red= n()) %>%
   data.frame()
  
  print("Summary of N positions per fish, after filtering at HPE<0.5")
  summary(red.npf$npos.red)   

```

## create plots of spatial errors, original, rejected, and retained
```{r Fig 9, echo=FALSE}
# read in the river channel and project properly
  riverbank = readOGR(dsn="GIS/2004_channel", layer="2004_channel_freTightclipWGS84")
     # convert to be useful in ggplot; still not sure what this actually does       
      ggriverbank <- fortify(riverbank, region="BYDEL")
  
    # create the constant theme and plots      
    roundfunc <- function(l) { (l <- round(l, 3))}  
    commonTheme = list(labs(color="Density",fill="Density",
                x="Longitude", y="Latitude"),
           theme_bw(),
           theme(legend.position=c(0,1),
                 legend.justification=c(0,1)))
    
      alldfg.hpe = alldfg[order(alldfg$Hpes),]
      points.all = ggplot(data=alldfg.hpe[alldfg.hpe$Hpes<50,], aes(x=Longitude, y=Latitude)) +
            geom_point(aes(color=Hpes)) + scale_color_viridis() +
            coord_fixed(ratio=1) + 
            geom_path(data = ggriverbank, aes(long, lat, group=group)) +
            scale_y_continuous(label=roundfunc) +  
            scale_x_continuous(label=roundfunc) + 
            commonTheme + labs(color="HPEs")

     
      ptdens.keep =  ggplot(data=alldfg[alldfg$Hpes<0.5,], 
                              aes(x=Longitude,y=Latitude)) + 
            geom_point(alpha=.1, color="grey80") + 
            stat_density2d(aes(fill=..level..,alpha=..level..), 
                           geom='polygon',colour='black') + 
            scale_fill_continuous(low="white",high="blue") +
            guides(alpha="none") + coord_fixed(ratio=1) + 
            geom_path(data = ggriverbank, aes(long, lat, group=group)) +
            scale_y_continuous(label=roundfunc) +  
            scale_x_continuous(label=roundfunc) + 
            commonTheme + guides(fill=FALSE)

        ptdens.remove =  ggplot(data=alldfg[alldfg$Hpes>=0.5 & alldf$Hpes<500,], 
                                aes(Longitude,Latitude)) + 
            geom_point(alpha=.1, color="grey80") + 
            stat_density2d(aes(fill=..level..,alpha=..level..), 
                           geom='polygon',colour='black') + 
            scale_fill_continuous(low="white",high="red") +
            guides(alpha="none") + coord_fixed(ratio=1) + 
            geom_path(data = ggriverbank, aes(long, lat, group=group)) +
            scale_y_continuous(label=roundfunc, limits=range(ggriverbank$lat)) +  
            scale_x_continuous(label=roundfunc, limits=range(ggriverbank$long)) +
            commonTheme + guides(fill=FALSE)
        
        # print plots in proper grid
    plot_grid(ptdens.remove, ptdens.keep, labels = c("A", "B"), ncol=1, align="v")
    
    png("Graphics/Figure9_HPE_Spatial_Distn.png", width=8, height=6, units="in", res=600)
     ggdraw() +
       draw_plot(points.all, x=0, y=0,width=0.6, height=1) +
       draw_plot(ptdens.remove, x=0.62, y=0.5,width=0.38, height=0.5) +
       draw_plot(ptdens.keep,   x=0.62, y=0,  width=0.38, height=0.5) + 
       draw_plot_label(c("A", "B", "C"), x = c(0,.62,.62), y = c(1,1,0.5), hjust=-0.5, vjust=1, size=15)
      dev.off()
```    
```{r}
  save(reddf, file="Maestros/AllFishPrimaryFilt.RData")
```
## End of Primary Filtering Process

***

# Beginning of Secondary Filtering Process

## Excessive Speeds Filtering
- Use primary filtered dataset created above
- Use adehabitatLT to calculate distance and speed between consecutive positions
```{r, echo=FALSE}
  load("Maestros/AllFishPrimaryFilt.RData") # object called 'reddf'

  # Critical to order this properly for the ordered step analysis below (TypeI)
  reddf = reddf[order(reddf$Id, reddf$Time),]  
  reddf$IDcol = 1:nrow(reddf)

  # convert the Lat Long into UTMs using 'sp'
  reddf.sp <- SpatialPointsDataFrame(coords = reddf[,c("Longitude","Latitude")], 
              data = reddf, 
              proj4string=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
        # confirmed string with VEMCO; the XY coords in azimuthal equal area
  options(digits=10)
  reddf.utm <- spTransform(reddf.sp, 
                          CRS("+proj=utm +zone=10 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"))
  reddf.utm@data[,c("east","north")] <- reddf.utm@coords
 
  reddf2 = reddf.utm@data    
 
  # calculate speed and distance with adehabitatLT
  red.ltraj = as.ltraj(xy=reddf2[,c("east","north")], date=reddf2$Time, 
                        id=reddf2$Id, infolocs = reddf2[,c("Id","Hpes","east","north")])
 
  red2 = ld(red.ltraj)
  red2$spd_mps = red2$dist / red2$dt
```
- Idenitfy consecutive positions resulting in excessive speeds (top 1%, 7.7mps)  --- *consider other justfication for 'excessive' speed threshold?*
- Position only considered 'bad' if both the step to and the step from the position have excessive speeds. 
```{r}
  # identify 'bad' positions (99%ile of step-speeds is ~7.7mps
  red2$prevspd = lag(red2$dist)/lag(red2$dt)

  red2$badpos <- 0
   red2$badpos[red2$spd_mps>7.7 & red2$prevspd>7.7] <- 1

  # filter out bad positions    
  red3 = red2[red2$badpos==0,]
 
  # recalculate speed and distance
  red3.ltraj = as.ltraj(xy=red3[,c("east","north")], date=red3$date, 
                        id=red3$Id, infolocs = red3[,c("Id","Hpes","east","north")])
 
  red4 = ld(red3.ltraj)
  red4$spd_mps = red4$dist / red4$dt
  
  save(red4, file="Maestros/AllFish_FiltSec1Speed.RData")
```
```{r, echo=FALSE}
  # N fish & total N positions
   print(paste0(nrow(red4)," positions")) 
    print(paste0("   ",round(nrow(red4)/nrow(alldfg)*100,2), "% of fish tag positions"))  
   print(paste0(length(unique(red4$Id))," individual fish"))  
    print(paste0("   ",round((length(unique(red4$Id))/length(unique(alldf$Id)))*100,1),"% of individual fish retained "))
   
   
  # N pos per fish after HPE filtering
  red4.npf = red4 %>%
   group_by(Id) %>%
   summarize(npos.red4= n()) %>%
   data.frame()
  
  print("Summary of N positions per fish, after filtering excessive speeds")
  summary(red4.npf$npos.red4)   

```

## Remove fish which departed from and returned again to array
- Remove select bursts for fish returning to array after some time absent (here use 6 hrs)
- Identified fish track segments to remove manually in external code
```{r}  
dt_threshold = 6*3600  # 6 hours

dtcut = function(dt) { return (dt > dt_threshold) } 

red4.ltraj = dl(red4)
red5.ltraj <- cutltraj(red4.ltraj, "dtcut(dt)", nextr=TRUE)

red5 = ld(red5.ltraj)

red5 = red5[!(red5$burst %in% c(36472.2, 36472.3, 36472.4, 36612.2, 36612.3)),]

save(red5, file="Maestros/AllFish_FiltSec2Pred.RData")
```
```{r, echo=F}
  # N fish & total N positions
   print(paste0(nrow(red5)," positions")) 
    print(paste0("   ",round(nrow(red5)/nrow(alldfg)*100,2), "% of fish tag positions"))  
   print(paste0(length(unique(red5$Id))," individual fish"))  
    print(paste0("   ",round((length(unique(red5$Id))/length(unique(alldf$Id)))*100,1),"% of individual fish retained "))
   
   
  # N pos per fish after HPE filtering
  red5.npf = red5 %>%
   group_by(Id) %>%
   summarize(npos.red5= n()) %>%
   data.frame()
  
  print("Summary of N positions per fish, after filtering return trips to array")
  summary(red5.npf$npos.red5)   

```

## Remove fish demonstrating suspicious holding behavior
- See "Exploration_DataFilteringPreds" for more on these three tracks.
__Should revisit this - these might be milling smolts, but might also be a predator__
```{r}
red6 = red5[!(red5$Id %in% c(36379,36483,36675)),]
save(red6, file="Maestros/AllFish_FiltSec3Hold.RData")
```
```{r, echo=FALSE}
  # N fish & total N positions
   print(paste0(nrow(red6)," positions")) 
    print(paste0("   ",round(nrow(red6)/nrow(alldfg)*100,2), "% of fish tag positions"))  
   print(paste0(length(unique(red6$Id))," individual fish"))  
    print(paste0("   ",round((length(unique(red6$Id))/length(unique(alldf$Id)))*100,1),"% of individual fish retained "))
   
   
  # N pos per fish after removed suspiscious fish
  red6.npf = red6 %>%
   group_by(Id) %>%
   summarize(npos.red6= n()) %>%
   data.frame()
  
  print("Summary of N positions per fish, after filtering fish with suspicious holding behaviors")
  summary(red6.npf$npos.red6)   

```

## Cut tracks into sub-bursts when gaps are > a selected threshold to avoid interpolating over long distances
#### These tracks will not be used for spatial aggregation, only for speed and turning angle analyses. 
- For now I've used 50m gaps until I make time to evaluate this more deeply.
- This results in a few sub-bursts that retain <4 positions; these are automatically dropped by adehabitatLT (a total of 166 positions)
- Reference back to final few code chunks in "Exploration_TrackGapBias" for more details on how to select this threshold.
``` {r, warning=FALSE}
dist_threshold = 50
distcut = function(dist) { return (dist > dist_threshold) } 

red6.ltraj = as.ltraj(xy=red6[,c("east","north")], date = red6$date, id = red6$Id, infolocs=red6[,c("Hpes","east","north")])
red7.ltraj <- cutltraj(red6.ltraj, "distcut(dist)", nextr=TRUE)

red7 = ld(red7.ltraj)
  red7$spd_mps = red7$dist / red7$dt
  
 # N fish & total N positions
   print(paste0(nrow(red7)," positions")) 
    print(paste0("   ",round(nrow(red7)/nrow(alldfg)*100,2), "% of fish tag positions"))  
   print(paste0(length(unique(red7$Id))," individual fish"))  
    print(paste0("   ",round((length(unique(red7$id))/length(unique(alldf$Id)))*100,1),"% of individual fish retained "))  
  
save(red7, file="Maestros/AllFish_FiltSec4Bursts.RData")
```



## Plot of pre- & post-filtering positions 
```{r, echo=FALSE, warning=FALSE, fig.height=8, fig.width=10}
 river3 = readOGR("C:/Users/Anna/Documents/GitHub/Fremont16/GIS/2004_channel","2004_channel_freTightclip")
  f_river3 <- fortify(river3, region="BYDEL")

pre.plot <- ggplot(data = alldf.utm[alldf.utm$Hpes<50,], aes(x=east, y=north, colour=Hpes)) + geom_point(alpha=0.2) + 
  scale_color_gradientn(colors=viridis(5)) +  ggtitle("Pre-Filtering") +
  geom_path(data = river3, aes(long, lat), col="gold", size=1.2 )+
  xlim(river3@bbox[1,1]+50, river3@bbox[1,2]) + ylim(river3@bbox[2,1], river3@bbox[2,2]) +
  coord_fixed()

post.plot <- ggplot(data = red7, aes(x=east, y=north, colour=Hpes)) + geom_point(alpha=0.2) + 
  scale_color_gradientn(colors=viridis(5)) + ggtitle("Post-Filtering") +
  geom_path(data = river3, aes(long, lat), col="gold", size=1.2 )+
  xlim(river3@bbox[1,1]+50, river3@bbox[1,2]) + ylim(river3@bbox[2,1], river3@bbox[2,2]) +
  coord_fixed()

par(mar=c(5.1,4.1,4.1,3.1))
plot_grid(pre.plot, post.plot, nrow=2)

png("Graphics/Fig9_SpatialError_pt2.png", width=5, height=9)
 plot_grid(pre.plot, post.plot, nrow=2)
dev.off()


```



## Remove tracks with >150 m gaps to avoid interpolating over long distances
#### These tracks will ONLY be used for spatial aggregation purposes (temp gaps redisc)
- For now I've used 50m gaps until I make time to evaluate this more deeply.
- This results in a few sub-bursts that retain <4 positions; these are automatically dropped by adehabitatLT (a total of 166 positions)
- Reference back to final few code chunks in "Exploration_TrackGapBias" for more details on how to select this threshold.
``` {r, warning=FALSE}
gap_threshold = 150
#gapcut = function(gap) { return (gap > gap_threshold) } 

red6.ltraj = as.ltraj(xy=red6[,c("east","north")], date = red6$date, id = red6$Id, infolocs=red6[,c("Hpes","east","north")])

 red8 = ld(red6.ltraj)
 
 # look at where 150 is in the histogram and ecdf, and consider other thresholds
 hist(red8$dt, xlim=c(0,500), ylim=c(0,450), breaks=100)
  abline(v=95, col="red")
  abline(v=150, col="red")
 plot(sort(red8$dt), (1:sum(!is.na(red8$dt)))/sum(!is.na(red8$dt)), type="s")
  abline(v=15, col="red")
  abline(v=150, col="red")
  abline(v=90, col="red")
     # other thresholds might be better, but because we used 150 in 2015 we'll stick with that to make the analyses comparable...
  
  longgaps = red8[red8$dt>=gap_threshold,]; longgaps = longgaps[!is.na(longgaps$id),]
   gapids = unique(longgaps$id) #56 tags (13% of 430 tags detected in rel 1 & 2
    
  red9 = red8[!(red8$id %in% gapids),]
  
save(red9, file="Maestros/AllFish_FiltSec5Gaps.RData")
``` 

